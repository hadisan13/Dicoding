{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP29TLcn7fkfEO+nWPejfts",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadisan13/Dicoding/blob/main/Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT464zHiHPvE",
        "outputId": "d7ac5374-bfd1-4f1d-de77-889ce8623e9d"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQYbHRbd27AJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcf79d4-fb7b-41dc-ed9e-93bc112b0e00"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "import os\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KvBElcVax-A",
        "outputId": "fc178d13-8554-4c6c-c044-7619d2485a5d"
      },
      "source": [
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Device:', tpu.master())\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "except:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: grpc://10.100.33.130:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.33.130:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.33.130:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of replicas: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqEGHl6P3cQi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bcff5c60-956d-4b1b-ff41-7dd0d9054880"
      },
      "source": [
        "train_df = pd.read_csv(r'/content/Corona_NLP_train.csv', encoding='latin_1')\r\n",
        "test_df = pd.read_csv(r'/content/Corona_NLP_test.csv', encoding='latin_1')\r\n",
        "\r\n",
        "df = pd.concat([train_df, test_df], ignore_index=True)\r\n",
        "\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44950</th>\n",
              "      <td>3794</td>\n",
              "      <td>48746</td>\n",
              "      <td>Israel ??</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44951</th>\n",
              "      <td>3795</td>\n",
              "      <td>48747</td>\n",
              "      <td>Farmington, NM</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44952</th>\n",
              "      <td>3796</td>\n",
              "      <td>48748</td>\n",
              "      <td>Haverford, PA</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44953</th>\n",
              "      <td>3797</td>\n",
              "      <td>48749</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Gov need to do somethings instead of biar je r...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44954</th>\n",
              "      <td>3798</td>\n",
              "      <td>48750</td>\n",
              "      <td>Arlington, Virginia</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>I and @ForestandPaper members are committed to...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44955 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       UserName  ...           Sentiment\n",
              "0          3799  ...             Neutral\n",
              "1          3800  ...            Positive\n",
              "2          3801  ...            Positive\n",
              "3          3802  ...            Positive\n",
              "4          3803  ...  Extremely Negative\n",
              "...         ...  ...                 ...\n",
              "44950      3794  ...            Positive\n",
              "44951      3795  ...            Negative\n",
              "44952      3796  ...             Neutral\n",
              "44953      3797  ...  Extremely Negative\n",
              "44954      3798  ...  Extremely Positive\n",
              "\n",
              "[44955 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QY_LRmW3nGc"
      },
      "source": [
        "coret = ['UserName', 'ScreenName', 'Location', 'TweetAt']\r\n",
        "df.drop(columns=coret, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_45AgrqphI1P"
      },
      "source": [
        "def change_sen(sentiment):\r\n",
        "    if sentiment == \"Extremely Positive\":\r\n",
        "        return 'positive'\r\n",
        "    elif sentiment == \"Extremely Negative\":\r\n",
        "        return 'negative'\r\n",
        "    elif sentiment == \"Positive\":\r\n",
        "        return 'positive'\r\n",
        "    elif sentiment == \"Negative\":\r\n",
        "        return 'negative'\r\n",
        "    else:\r\n",
        "        return 'netural'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05mpp5uXKo1c"
      },
      "source": [
        "X_raw = df['OriginalTweet']\r\n",
        "Y_raw = df['Sentiment']\r\n",
        "\r\n",
        "Y_raw = Y_raw.apply(change_sen)\r\n",
        "\r\n",
        "category = pd.get_dummies(Y_raw)\r\n",
        "Y = pd.concat([Y_raw, category], axis=1)\r\n",
        "Y.drop(columns = ['Sentiment'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l6ASTxJc5ka"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "stop = stopwords.words('english')\r\n",
        "def clean(text):\r\n",
        "    # specific\r\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\r\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\r\n",
        "\r\n",
        "    # general\r\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\r\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\r\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\r\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\r\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\r\n",
        "    # remove url\r\n",
        "    #         text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\r\n",
        "    text = re.sub(r'http\\S+', '', text)\r\n",
        "    # remove @\r\n",
        "    text = re.sub(r'@\\w+', '', text)\r\n",
        "    # remove #\r\n",
        "    text = re.sub(r'#\\w+', '', text)\r\n",
        "    \r\n",
        "    text = re.sub(r'<.*?>', '', text)\r\n",
        "        \r\n",
        "    text = text.split()\r\n",
        "        \r\n",
        "    text = ' '.join([word.lower() for word in text if word.lower() not in stop])\r\n",
        "        \r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-uekBODHMJR"
      },
      "source": [
        "X = X_raw.apply(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmYL3U8uVDX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ppR1QZCDGr"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "\r\n",
        "word_index = tokenizer.word_index\r\n",
        "\r\n",
        "max_len = max(X_train.apply(len))\r\n",
        "\r\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "sequences_val = tokenizer.texts_to_sequences(X_val) \r\n",
        "\r\n",
        "X_train_padded = pad_sequences(sequences_train, max_len, padding='post')\r\n",
        "X_val_padded = pad_sequences(sequences_val, max_len, padding='post')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrlrxMaAHZwo"
      },
      "source": [
        "# Modelling starts with GloVe pre-trained 100\r\n",
        "embedding_dict={}\r\n",
        "with open('/content/glove.6B.100d.txt','r',encoding='utf-8') as f:\r\n",
        "    for line in f:\r\n",
        "        values=line.split()\r\n",
        "        word=values[0]\r\n",
        "        vectors=np.asarray(values[1:],'float32')\r\n",
        "        embedding_dict[word]=vectors\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwDInSqGRsJw"
      },
      "source": [
        "num_words=len(word_index)+1\r\n",
        "embedding_matrix=np.zeros((num_words,100))\r\n",
        "\r\n",
        "for word,i in word_index.items():\r\n",
        "    if i > num_words:\r\n",
        "        print(\"Inside i greater than\")\r\n",
        "        continue\r\n",
        "    \r\n",
        "    emb_vec=embedding_dict.get(word)\r\n",
        "    if emb_vec is not None:\r\n",
        "        #print(\"i =\" , i)\r\n",
        "        embedding_matrix[i]=emb_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP4zemtRRxM7"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(len(word_index) + 1,\r\n",
        "                                            100,\r\n",
        "                                            weights=[embedding_matrix],\r\n",
        "                                            input_length=max_len,\r\n",
        "                                            trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPVSlqOxSNka"
      },
      "source": [
        "def My_Model():\r\n",
        "\r\n",
        "  result = tf.keras.Sequential([\r\n",
        "    embedding_layer,\r\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, recurrent_dropout=0.4)),\r\n",
        "    tf.keras.layers.GlobalMaxPool1D(),\r\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tf.keras.layers.Dropout(0.4),\r\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\r\n",
        "  ])\r\n",
        "\r\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zTwMnoVUIo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd49390-2f0c-4673-cf93-abc54ffd1278"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model = My_Model()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 286, 100)          3126000   \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 286, 256)          234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_11 (Glo (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 3,377,139\n",
            "Trainable params: 251,139\n",
            "Non-trainable params: 3,126,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTt_jHwUP_x"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKzvhxlEVCjH",
        "outputId": "38dfb854-77d6-4370-ee3a-0863748e43c1"
      },
      "source": [
        "history = model.fit(X_train_padded, y_train, epochs = 20, validation_data = (X_val_padded, y_val), batch_size = 64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "450/450 [==============================] - 36s 65ms/step - loss: 0.8736 - accuracy: 0.5944 - val_loss: 0.6619 - val_accuracy: 0.7272\n",
            "Epoch 2/20\n",
            "450/450 [==============================] - 25s 55ms/step - loss: 0.6459 - accuracy: 0.7404 - val_loss: 0.5800 - val_accuracy: 0.7670\n",
            "Epoch 3/20\n",
            "450/450 [==============================] - 25s 55ms/step - loss: 0.5490 - accuracy: 0.7881 - val_loss: 0.5436 - val_accuracy: 0.7833\n",
            "Epoch 4/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.4727 - accuracy: 0.8274 - val_loss: 0.5179 - val_accuracy: 0.8023\n",
            "Epoch 5/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.4133 - accuracy: 0.8536 - val_loss: 0.5298 - val_accuracy: 0.7984\n",
            "Epoch 6/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.3510 - accuracy: 0.8791 - val_loss: 0.4938 - val_accuracy: 0.8172\n",
            "Epoch 7/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.2884 - accuracy: 0.9035 - val_loss: 0.5153 - val_accuracy: 0.8155\n",
            "Epoch 8/20\n",
            "450/450 [==============================] - 25s 55ms/step - loss: 0.2519 - accuracy: 0.9166 - val_loss: 0.5549 - val_accuracy: 0.8062\n",
            "Epoch 9/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.2089 - accuracy: 0.9321 - val_loss: 0.5729 - val_accuracy: 0.8119\n",
            "Epoch 10/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.1807 - accuracy: 0.9403 - val_loss: 0.6001 - val_accuracy: 0.8113\n",
            "Epoch 11/20\n",
            "450/450 [==============================] - 25s 55ms/step - loss: 0.1618 - accuracy: 0.9458 - val_loss: 0.6518 - val_accuracy: 0.8043\n",
            "Epoch 12/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.1369 - accuracy: 0.9550 - val_loss: 0.7026 - val_accuracy: 0.8132\n",
            "Epoch 13/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.1176 - accuracy: 0.9607 - val_loss: 0.7086 - val_accuracy: 0.8058\n",
            "Epoch 14/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.1084 - accuracy: 0.9628 - val_loss: 0.7946 - val_accuracy: 0.7991\n",
            "Epoch 15/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.0968 - accuracy: 0.9677 - val_loss: 0.8463 - val_accuracy: 0.8058\n",
            "Epoch 16/20\n",
            "450/450 [==============================] - 25s 55ms/step - loss: 0.0923 - accuracy: 0.9668 - val_loss: 0.8123 - val_accuracy: 0.8081\n",
            "Epoch 17/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.0790 - accuracy: 0.9732 - val_loss: 0.8964 - val_accuracy: 0.7909\n",
            "Epoch 18/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.0785 - accuracy: 0.9733 - val_loss: 0.8686 - val_accuracy: 0.8029\n",
            "Epoch 19/20\n",
            "450/450 [==============================] - 25s 57ms/step - loss: 0.0729 - accuracy: 0.9752 - val_loss: 0.9939 - val_accuracy: 0.7988\n",
            "Epoch 20/20\n",
            "450/450 [==============================] - 25s 56ms/step - loss: 0.0687 - accuracy: 0.9760 - val_loss: 1.0035 - val_accuracy: 0.8040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G1c3IGQVPn9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}